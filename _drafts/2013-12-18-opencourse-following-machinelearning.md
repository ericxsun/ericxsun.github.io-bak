---
layout: post
title: Machine Learning跟课计划
keywords: ["MOOC", "Machin Learning"]
description: "Machine Learning 跟课计划"
categories: ["mooc", "machine learning"]
tags: ["plan"]
---

2014-01-05 更新

今天完整学完了Ng的Machine Learning这门课。

有一个问题一直没明白。在Neural Networks Learning这一节的一个程序"checkNNGradients.m"中

{% highlight matlab %}
diff = norm(numgrad-grad)/norm(numgrad+grad);
{% endhighlight %}

用以衡量两个梯度的差异。通过我们直接用norm(numgrad-grad)就可以。但为什么他要再除一个norm(numgrad+grad)呢？

是相对误差与绝对误差的区别?

-----

即将完整学完[Andrew Ng](http://ai.stanford.edu/~ang/)的[Machine Learning](https://class.coursera.org/ml-004)课，这个课应该算入门吧。接下来将学习[Artificial Intelligence Planning](https://www.coursera.org/course/aiplan)。这门课将在2014年1月13号开课，Google大牛亲自授课，亲自参与线上国际合作项目，还有证书拿，嘿嘿。

PUSH PUSH.

Ask, and it shall be given; seek, and you shall find; knock, and it shall be opened to you.