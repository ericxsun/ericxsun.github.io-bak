---
layout: post
title: (转)认知、流形与虚实世界
keywords: ["认知", "流形", "虚实世界"]
description: "从第一代单层神经网络被称为“感知机“开始，人工智能学者不断地追求强有力的方法来感知、认知这个复杂的 世界。（由于语义在各种语境下的混淆，这里我们不讨论认知（Cognition）与感知(Perception)的差异）。统计机器学习方法从线性方 法，到浅层非线性学习，再发展到当前的深度学习的历程中，数据吞吐处理能力，函数逼近能力，以及方差控制方法都得到了长足的进步。近期，机器已经可以在给 定自然场景图片集合上识别效果完爆人类，这是否表明机器已经可以认知我们这个复杂的自然场景世界呢？又有研究报告机器很容易被欺骗，对毫无意义的图片给出 置信度极高的结果，这意味着什么？在榜单频繁被刷爆的今天，我们除了跟风刷榜之外，还有那些更本质，更有意义的工作可以去做呢？"
categories: ["AI"]
tags: ["Cognition", "Manifold", "VR"]
---

本文系转载，原文请移步[认知、流形与虚实世界](http://zero2one.farbox.com/post/2015-05-05)


从第一代单层神经网络被称为“感知机“开始，人工智能学者不断地追求强有力的方法来感知、认知这个复杂的 世界。（由于语义在各种语境下的混淆，这里我们不讨论认知（Cognition）与感知(Perception)的差异）。统计机器学习方法从线性方 法，到浅层非线性学习，再发展到当前的深度学习的历程中，数据吞吐处理能力，函数逼近能力，以及方差控制方法都得到了长足的进步。近期，机器已经可以在给 定自然场景图片集合上识别效果完爆人类，这是否表明机器已经可以认知我们这个复杂的自然场景世界呢？又有研究报告机器很容易被欺骗，对毫无意义的图片给出 置信度极高的结果，这意味着什么？在榜单频繁被刷爆的今天，我们除了跟风刷榜之外，还有那些更本质，更有意义的工作可以去做呢？

本文试图对上面的问题进行一些讨论，并抛砖引玉，请方家指正。

## 认知过程

从数据中获取认知，是人们的追求。我们追求的，不是记住图像的每个像素、每个音节，而是隐含在数据背后，那更本质，能够使我们做出预测的东西。当我 们能够从纷繁复杂的世界中辨识出一个目标，并能预测这个目标在外部因素变化情况下发生的变化，我们便可以认为我们拥有了这个目标的完整认知。

举 个例子。对世间万物，映入我们眼帘那一刻，我们的脑海便形成了认知，可能包含几个层面的信息：类别（人，或桌子），姿态（站立，坐着），颜色，方位等等。 依据这些信息，人脑对当前状况做出了判断，** 并可以对未来状态进行预测 **。比如，如果那个人往左移动1米，那么这个场景我是可以构想并绘画出来的。这是人脑这个认知系统的基本能力。

仔细观察这个过程，我们可以把它拆解成两个部分：

 - 匹配过程：输入一副图像，人脑对其中的不变量（比如生物体的类别模式）进行模式匹配，分离出变量，形成若干个核心维度（比如当前桌子的位置）的认识。
 - 预测过程：当核心维度变量发生变化时，人脑将其与固定模式进行融合，产出预测。

当一个算法能够完美地完成这两个过程，我们可以认为该算法已经形成了对该数据的完整认知。

那么，我们现在的机器学习系统，比如近期火爆的在ImageNet上取得突破的深度神经网络，是否形成了对自然场景的完整认知呢？我们来看深度神经网络在ImageNet任务上，对两个过程的完成情况：

 - 匹配过程：我们训练ImageNet的时候，只会输出目标的类别，而不会输出目标的姿态，位置信息。深度学习系统对模式分类任务完成很好，但是没有对物体的内在核心维度的认知。
 - 预测过程：由于不存在核心维度的认知，故也无法对核心维度发生变化时做出预测。

因此，ImageNet任务上训练的深度神经网络，并没有完成整个认知过程。当然这首先是任务目标本身决定的。那么另外一个以brain命名的项 目，Google Brain又如何呢？GoogleBrain以能够自动发现猫脸而著称于世。Google Brain 在图像中识别出猫脸的时候，它的确完成了部分匹配过程。但是，它并没有展现出能够预测一个猫在各种形态下的图像的能力。因此仅根据当前披露的事实，它并没 有关于“猫”的完整认知。

在继续讨论完整认知之前，先要回答必要性的问题。我们这里强调完整认知过程，是否有必要？这是否是一个心理学家，或者某某主义的信徒所纠结，但应该被我们这些实践者所鄙视的话题？

我认为，这个问题是实践者同样需要关注的问题。首先，一些人工智能应用需求本身需要完整认知过程。一个典型的场景即无人驾驶汽车，它必须对整个道路环境有全 景式的认知，即辨识出所有的物体，并对其中一些物体的当前状态要素（位置，速度）做出估计，并做出未来一段时间的预测。如果某种方法论，强调能够end to end实现这种智能系统（正如深度学习的拥趸所坚信），那么这种方法论必须解决完整认知过程的实现问题。其次，认知的能力是一个整体。即便对于仅关注模式 分类的应用场景，对核心变量与预测过程的重视，也将有助于分类任务的性能提升。这一点已有不少证据，容后文再秉。

从现在开始，我们将讨论完整认知过程的实现问题。匹配过程与预测过程的纽带，是对认知对象的不变量与核心变量进行建模。曾经有一个研究领域，提出了对认知的不变量与变量建模的方法论，那就是流形学习。

## 流形学习

机器学习任务通常假设数据都位于欧式空间中。既然该数据成为一个学习目标，该数据集一定具有某种的内在不变性，且具有导致其变化的核心要素集合。适 合该情况的典型数学模型就是流形。即，我们假设数据是位于一个嵌入在高维欧式空间的流形上的。流形本身决定了数据集的不变性，而流形上的坐标则对应于那些 核心变量因素。

采用流形建模方式，那么典型的目标分类任务中每个需要辨识的类别对应一个流形。流形学习方法论对认知过程的实现过程如下：

 - 匹配过程：寻找距离某个物体最近的流形的过程，物体在该流形上的投影坐标即该物体的核心变量；
 - 预测过程：连续地改变该物体的投影坐标值，那么该物体将在流形上移动，产出预测。

因此，只要我们能够从数据中学习到正确的流形，那么这个认知过程就是完整的。

流形学习的思想由来已久。在80年代，Hestie提出 了Principal Curve/Surface 的思想。更早的Auto-Encoder 可以看做是流形学习的一种实现。虽然80-90年代，不断有学者提出非线性PCA的算法，很多也提到surface，manifold的概念，但无一个方 法能够足够有影响，能够创立并支持Manifold Learning 这个领域。原因很简单，没有任何一个算法能够在哪怕最简单的Toy曲面上得到好的效果。Hastie 的Principal Curve 只能逼近一维流形数据，且很容易陷入局部极小问题，无法学到数据的高维流形结构；神经网络方法整体被人遗忘，AE在真实数据上表现不佳，同样非常容易陷入 局部极小；KPCA 受限于Kernel 框架，即便在众多学者在Data Dependent Kernel 及其优化上投入了大量精力的情况下，它在很多数据，甚至Toy 曲面上也没有很好的结果。因此，对于一个连Toy问题都没有处理好，大家看不到任何希望的领域，似乎也没有必要专门提出一个领域进行专门的研究了。

然而，2000年12月science 杂志上发表的三篇论文改变了这一切。在这三篇论文中，两篇算法论文给出了无与伦比的优美结果，另外一篇则是神经科学家的背书。于是，简单而优雅的新算 法，Toy问题被麻溜地解决，而且带有那么一点对计算机领域来说形而上色彩的生理学依据。吸引研究人员的所有必要条件都已具备。由此，“流形学习”这个新 领域便诞生了。

流形学习的肇始方法，LLE 与 ISOMap 的思想，都源自流形的基本定义：局部同构于欧式空间。利用这一点，可以使用传统欧式空间中线性方法得到局部的变量因素，然后利用全局连通性等约束以及一些 全局目标优化，可以得到整个流形结构上的变量因素。在数学上，这两个方法与经典的MDS并没有太多不同，仅仅是个特征值问题而已。然而，使用如此简单的数 学方法，仅仅利用局部结构穿起整个全局结构的思路，便给非线性非监督学习的一个重要问题——初始化问题的解决，带来了希望。（联想到DNN也是从初始化入 手引起关注，可见人们对非线性学习的初始化问题是多么的痛恨。）

希望如此之大，研究人员便像飞蛾扑火一样义无反顾投身其中开始灌水。一时间 各大会议，Transaction都布满了被摊平的奇形怪状的曲面，以及各种姿态的茶壶与人头图像序列。LTSA，LE等可以比肩LLE，ISOMap的 方法不断被提出，而在姿态识别，光源定位等方面的进展似乎也预示着这一套路的流形学习方法必将大行其道，将计算机的认知水平提上一个台阶。

然而，这一切并没有发生。尽管流形学习的文章在Pami上一直持续到10年代，并且其线性化方法在小样本人脸识别问题上的研究持续得更久，但流形学习的研究在逐步冷却。这种冷却，不是逐步冷静后积蓄力量的冷却，而是撞到南墙后无望离去的冷却。

这 种冷却显然是由于流形学习在一些真实任务中败北造成的。在品质良好的实验室数据之外的真实数据上，LLE/ISOMap系列的流形学习算法几乎无一例外全 面败北。Bengio 在《Non-Local Manifold Tangent Learning》一文中已经明确指出，局部的流形学习方法在现实任务中失败的原因有：

 - 流形附近的高噪声干扰；
 - 流形的高曲率；
 - 流形的高内在维度；
 - 存在多流形导致针对每个流形的样本偏少。

其中，前两者在现实工作中的表现，即为样本集合的近邻相似度估计不准。这对LLE/ISOMap等高度依赖局部相似邻域的算法是致命的问题。局部邻域估计不准确，造成了流形切空间的不光滑，最终导致模型稳定性和推广型极差。

而后两点，则涉及机器学习方法的基本困难。这里容后再表。

Bengio 的这篇论文发表在 2005年。它实际上宣判了LLE/ISOMap 系列方法，即主流流形学习方法的死刑。流形学习方法的研究又持续了5年，期间很多论文没有引用Bengio的相关研究。这应该是为了保持自己研究正当性所 采取的刻意的冷遇措施。但无论如何，LLE/ISOMap方法的确死了。尽管在研究高维空间流形逼近的主流形领域，证明了面向认知任务的一维最优流形的存 在性，但缺乏高维曲面的数学工具，没法推广到高维流形，而且也没有引发能够解决上述问题的新方法出现。由于Deep方法的快速兴起，光芒掩盖了其他领域的 进展，因此流形学习领域的主流方法死掉，也并未引起多少关注。

## 新时代

2006年，Deep Learning 首先以一个Deep AutoEncoder 的形式登场亮相。如前所属，Auto-Encoder可以看做一个很好的流形学习实现机制。而且从理论上说，Bengio指出的LLE/ISOMap方法 失败的原因，在深度学习框架下得到了很大的缓解：

 - 流形附近的高噪声干扰：神经网络具有平滑的切空间，因此抗噪声能力更强；
 - 流形的高曲率：在同样样本情况下，深层模型可容纳的可变性更强。

但是，或许是由于流形学习方法与深度学习的结合，在数学上乏善可陈，也或许是，在大数据驱动下，深度学习在真实世界的模式识别任务上开始横扫领域专家，一定程度上掩盖了对认知全过程的迫切需求，深度流形学习的发展一直没有获得太多关注。

尽管如此，近期的一些研究，展示了流形学习思路，或者完整认知的思路，对匹配系统性能提升的必要性。例如：

 1. 基于Local Generalization（即流形学习所依赖的局部相似性）的非监督信息，给匹配阶段的学习提供了丰富的信息，以及强大的数据相关的正则化支持。例 如：DL系统在刷图像数据库时，普遍采用加噪声，生成伪标记样本的方式扩充样本集合，实际上是通过局部相似性对机器做了正则。另外，视觉领域，自然场景 下，获取局部相似性的可靠方法，便是依赖视频流时间局部性决定的相邻帧的相似性。结合目标检测等工具，相邻时间（甚至相当长一段时间）内同一目标的变化可 以认为是相似的数据。如果流形建模足够好，那么非监督信息的正则支持完全可以跨过小的局部邻域，而在大尺度上提供更强有力的正则支持。

 2. 匹配阶段需要预测阶段提供正则/约束支持。DNN可以轻易地被欺骗，导致对完全无意义的图片给出置信度极高的类别判断。这表明当前DNN的匹配模 型存在过学习现象，难以应对数据集之外丰富多彩的世界。对可变性要求极高的模型进行有效的正则，是难度很高的工作。通过加入预测阶段，丰富学习的内容，加 入对类别内部变化因素的学习，并建立预测阶段学习机器与匹配阶段学习机器的某种一致性约束（例如特征交互，参数相关等），或许可以缓解这类问题。或者换另 一种更常用的说法，Generative Model 更难以欺骗，可以用这个根儿奥体ve model来增强匹配阶段Discriminative Model的鲁棒性。Hinton的一篇论文标题《To Recognize Shapes, First Learn to Generate Images》的标题也正是这个意思。最近Deep Mind的Draw系统开始研究图片生成，的确在某种程度上起到了提升噪声数字分类准确率的效果。

但是整体上来说，当前主流研究范式中，匹配过程与预测过程仍然是割裂的，并未采用内在的流形结构将二者组合成为一个整体。这其中的困难有：

 - 困难一：多流形及其内在核心变量的建模。自然场景下，目标个数是可变的，因此系统需要能够处理可变个流形的表示与匹配问题；每个流形的内在核心变量建模是不同维度，且需要各自标定的。

 - 困难二：预测过程的学习困难。预测过程学习的核心是对变更核心变量引发的预测结果给出是否符合预期的判断及其误差。由于流形的高曲率，简单依赖测 试样本附近的重构误差不是一个足够精确的方案。为得到一个鲁棒的认知系统，我们需要更加准确，且适应性更广，能够跳出训练样本附近，对更主动，更随意变更 核心变量的行为后果做出准确的判断。

此外，Bengio指出的流形学习所面临的问题中3)，4）两点，维数灾难与样本缺乏，是困扰机器学习的基本问题，也应列入我们的困难之中。但是，为了避免讨论走向深度框架能够带来样本量指数减少这种毫无无意义的理论争论，这里宁愿从实践的角度对这个问题进行重新表述：

 - 困难三：系统所能处理的样本吞吐量受限。大数据以摧枯拉朽的方式摧毁了无数研究高维小样本场景的学者的生涯。然而，目前的大数据的量级，对于人的 认知成长过程中所经历的自然场景变化的信息洪流，又算得了什么？在超大样本量的情况下，维数灾难，甚至某些机器学习的不足（比如浅层）都将可能不是问题。

困难一，属于面向任务的特定困难。它不是通用方法论的困难，而是实践取舍的问题，并不是不可克服的。困难二实际上是对智能系统主动反馈的需求；困难三则要求系统的样本带宽要足够的大。后二者是对学习方法论的要求。简而言之一句话：

	鲁棒的认知系统学习过程需要对主动行为的高带宽准确反馈。

除去婴儿学习过程，这一人们容忍性极高的学习例子，目前唯一能够满足这一要求的可行学习场景，只有一个可能：虚拟世界。

## 虚实世界

游戏世界，是一个典型的具有大吞吐量，能够对用户主动行为进行奖惩反馈的场景。 而且Deep mind已经展示了可以通过Reinforcement Learning来学习最佳游戏方法的能力。

为了建造一个对现实世界中某项任务具有完整认知的AI系统，我们可以建造一个仿真系统，在系统中重现这个任务所面临的所有情况，将AI系统作为这个系统的一 个玩家，并根据任务目标来指定AI的各种行为的奖惩。目前，模拟现实的高仿真游戏很多，比如虚拟人生，极品飞车等。假想我们的AI系统是极品飞车中的一辆 赛车，它不是通过游戏内在API机制来进行环境感知，而是获取正如我们玩游戏时看到的自然场景图像；它触碰物体产生的效果变化，也只能通过视觉、听觉等来 得到反馈；它的行为的好坏，也将由由游戏规则判断。这样，对核心操作要素进行流形建模，结合Deep Learning处理目标匹配的强大能力，并通过Reinforcement Learning 的方式来学习主动行为的反馈，我们将得到一辆在极品飞车世界里长期占据冠军榜的赛车。假设我们开发一个极品飞车北京版，完整重现北京交通路线，不守规矩的 司机，乱穿马路的行人，拥堵龟速的通行方式，以及春夏秋冬雾霾不断的天气情况，那么指挥这辆车的AI系统，很大可能也能驾驶真实世界的汽车，开行在北京的 大街小巷。

大家一定会争论虚拟世界与真实世界的差异问题。首先，电影虚拟效果的真实感已经毋庸置疑，而游戏实时绘制场景的真实感追上电影 只是时间问题。现有的街景等系统，也对提升虚拟世界真实性有很大帮助。其次，虚拟世界的多样性和可能性远远高于真实世界，由于虚拟系统可以任意组合各种非 预期的最坏情况让AI学习，极品飞车里的AI至少要比新上路的马路杀手要靠谱很多。再次，可以用虚拟世界来发现什么样的辅助设施能够让机器人更好的工作， 来降低机器人在真实世界工作的难度。比如，加入身份识别系统让AI区分自动驾驶汽车和人驾驶汽车；增加道路信号标志以及道路传感器；增加人驾驶汽车的传感 器等等都能降低AI工作的难度。而何种配置能够达到经济效益最佳，在虚拟系统里只是几次虚拟运行而已。最后，即便在改造后的真实世界里，AI的运行不那么 完美，人们处于懒惰的本性，也会愿意改造自己来适应机器。这种事情已经反复发生了，比如搜索框里的非原文长query基本不是人话，并且我们对Siri的 指令也带有特殊的风味。

在虚拟世界中训练AI，并将它们应用在现实世界，或许是我们建立真正能够有效而可靠地工作的机器人的最低成本方式。

## 局限

我们把智能分为几个层面来看：一个是猫狗猴等哺乳动物层面的智能；一个是人独特的知识、语言，逻辑推理智能；最后，人的情感，艺术智能。上一段描述的虚拟世界构造方法方法能够实现什么层级的智能呢？

虚拟世界方案的核心在于，可以实现物理世界中的简单规律，从而以大吞吐量对主动行为进行奖惩反馈。因此，我们能够构造出类似猫狗猴等具有处理物理世界简单规律能力的智能系统，比如自动驾驶，图像识别等等。

但 在人类的知识，逻辑等层面，只有真人能够做出准确的反馈，因此虚拟世界的意义不大。因此，在这个层面上，AI系统的构造更依赖众包的人工反馈。正所谓有多 少人工就有多少智能。但众包系统的吞吐量仍然较小。这个层面上可靠的智能构造方法论还没有出现。知识图谱与NLP领域举步维艰的现状，正是这个原因。

而在情感、艺术层面，由于无法定义标准，任何反馈都失去了意义，正如多数人无法看懂现代艺术，以及你很难区分一个发疯的人的语言，和一台胡言乱语的机器。在这个层面上，人工智能并不是一个需要在实现方面考虑的良定义的问题。

## 结语

本文讨论了实现哺乳动物层面智能的一种途径。即通过流形建模连接匹配与预测过程，形成完整认知；通过深层神经网络解决模型容量以及光滑性问题；并通 过虚拟世界，解决高带宽主动探索反馈样本问题。正如大量标注的ImageNet等数据集使得Deep learning发挥了潜力，大幅提升了系统性能那样，虚拟世界将提供近乎无穷的训练样本，能够支撑流形认知模型的学习，形成对物理世界的完整认知智能。

虽然哺乳动物的智能看起来并不起眼，人类也不会被哺乳动物层级的智能所威胁，但是人类社会的大部分工作所需要的只是哺乳动物感知世界的能力配合简单规则便可 实现的。互联网新经济的出现，已经未像传统工业进步那样增加就业，而具有哺乳动物智能的智能经济，则会显著减少就业需求。这是人类社会巨变的一个诱因，是 一万年未见之大变局。无就业人士是会被福利社会养起来，还是会被无情抛弃，那种选择都会是对人类现有社会心态的巨大挑战，人类社会也会彻底重塑。我等智能 经济从业人员，或许届时未被替换，但是希望那时政治家们能够负起责任，能够使我等避免类似奥本海默的良心谴责。

----
